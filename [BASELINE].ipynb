{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ywnSZDzDhwY"
   },
   "source": [
    "### 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nvSWaQMmDhwa"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# torch model 저장\n",
    "def model_save(model, score,  path):\n",
    "    os.makedirs('model', exist_ok=True)\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'score': score\n",
    "    }, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "d1D464OdB8Dt"
   },
   "outputs": [],
   "source": [
    "# fix seed\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lj8If10kDhwb"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob('train/*.png'))\n",
    "test_png = sorted(glob('test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lG0xfyFjDhwb"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaoJ-lThDhwb"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUf1kyFoDhwc"
   },
   "outputs": [],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_imgs_384', np.array(train_imgs))\n",
    "np.save('test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.load('train_imgs_384.npy')\n",
    "test_imgs = np.load('test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                     std = [0.181572, 0.174035, 0.163234]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "                                     std = [0.195055, 0.190053, 0.185323])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88, drop_path_rate = 0.1)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88, drop_path_rate = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGAMfbpoDhwe"
   },
   "outputs": [],
   "source": [
    "#class Custom_dataset(Dataset):\n",
    "#    def __init__(self, img_paths, labels, mode='train'):\n",
    "#        self.img_paths = img_paths\n",
    "#        self.labels = labels\n",
    "#        self.mode=mode\n",
    "#    def __len__(self):\n",
    "#        return len(self.img_paths)\n",
    "#    def __getitem__(self, idx):\n",
    "#        img = self.img_paths[idx]\n",
    "#        if self.mode=='train':\n",
    "#            augmentation = random.randint(0,3)\n",
    "#            if augmentation==1:\n",
    "#                img = img[::-1].copy()\n",
    "#            elif augmentation==2:\n",
    "#                img = img[:,::-1].copy()\n",
    "#            elif augmentation==3:\n",
    "#                img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "#            elif  augmentation==4:\n",
    "#                img = cv2.blur(img,(10,10))\n",
    "#            elif augmentation==4:\n",
    "#                img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "                       \n",
    "#        img = transforms.ToTensor()(img)\n",
    "#        img = transforms.Normalize([0.43309692, 0.40352088, 0.39421389], [0.18095295, 0.17348227, 0.16271882])(img)\n",
    "#        if self.mode=='valid':\n",
    "#            pass\n",
    "#        if self.mode=='test':\n",
    "#            pass\n",
    "        \n",
    "#        label = self.labels[idx]\n",
    "#        return img, label\n",
    "    \n",
    "#class Network(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super(Network, self).__init__()\n",
    "#        self.model = timm.create_model('efficientnet_lite0', pretrained=True, num_classes=88)\n",
    "        \n",
    "#    def forward(self, x):\n",
    "#        x = self.model(x)\n",
    "#        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVNhul5gDhwe"
   },
   "outputs": [],
   "source": [
    "# KFold\n",
    "#folds = []\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#for train_idx, valid_idx in kf.split(train_imgs):\n",
    "#    folds.append((train_idx, valid_idx))\n",
    "#fold=0\n",
    "#train_idx, valid_idx = folds[fold]\n",
    "\n",
    "\n",
    "#batch_size = 10\n",
    "#epochs = 40\n",
    "\n",
    "\n",
    "# Train\n",
    "#train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
    "#train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "# Validation \n",
    "#valid_dataset = Custom_dataset(np.array(train_imgs)[valid_idx], np.array(train_labels)[valid_idx], mode='valid')\n",
    "#valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "# Test\n",
    "#test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "#test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NU8CSwkDhwe"
   },
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/25    time : 386s/9258s\n",
      "TRAIN    loss : 1.22769    f1 : 0.18214\n",
      "Val    loss : 0.64904    f1 : 0.25837\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/25    time : 377s/8663s\n",
      "TRAIN    loss : 0.56710    f1 : 0.33233\n",
      "Val    loss : 0.45906    f1 : 0.39706\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/25    time : 379s/8334s\n",
      "TRAIN    loss : 0.39972    f1 : 0.49300\n",
      "Val    loss : 0.39391    f1 : 0.54554\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/25    time : 377s/7914s\n",
      "TRAIN    loss : 0.33171    f1 : 0.58484\n",
      "Val    loss : 0.29687    f1 : 0.57541\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/25    time : 378s/7554s\n",
      "TRAIN    loss : 0.23723    f1 : 0.67541\n",
      "Val    loss : 0.25391    f1 : 0.69890\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/25    time : 378s/7188s\n",
      "TRAIN    loss : 0.18800    f1 : 0.73965\n",
      "Val    loss : 0.23232    f1 : 0.72038\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/25    time : 381s/6851s\n",
      "TRAIN    loss : 0.15867    f1 : 0.78425\n",
      "Val    loss : 0.19364    f1 : 0.72365\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/25    time : 382s/6491s\n",
      "TRAIN    loss : 0.14528    f1 : 0.82381\n",
      "Val    loss : 0.19252    f1 : 0.75224\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/25    time : 378s/6045s\n",
      "TRAIN    loss : 0.11138    f1 : 0.86749\n",
      "Val    loss : 0.18841    f1 : 0.75918\n",
      "epoch : 10/25    time : 377s/5650s\n",
      "TRAIN    loss : 0.10770    f1 : 0.88339\n",
      "Val    loss : 0.25783    f1 : 0.73905\n",
      "epoch : 11/25    time : 376s/5268s\n",
      "TRAIN    loss : 0.09633    f1 : 0.88812\n",
      "Val    loss : 0.22398    f1 : 0.75208\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/25    time : 379s/4925s\n",
      "TRAIN    loss : 0.09509    f1 : 0.89466\n",
      "Val    loss : 0.15060    f1 : 0.76409\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/25    time : 379s/4550s\n",
      "TRAIN    loss : 0.07882    f1 : 0.92632\n",
      "Val    loss : 0.17195    f1 : 0.80834\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/25    time : 379s/4166s\n",
      "TRAIN    loss : 0.07426    f1 : 0.92210\n",
      "Val    loss : 0.16679    f1 : 0.83540\n",
      "epoch : 15/25    time : 377s/3775s\n",
      "TRAIN    loss : 0.05315    f1 : 0.93241\n",
      "Val    loss : 0.15996    f1 : 0.78102\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/25    time : 381s/3428s\n",
      "TRAIN    loss : 0.06363    f1 : 0.93907\n",
      "Val    loss : 0.15676    f1 : 0.84324\n",
      "epoch : 17/25    time : 379s/3029s\n",
      "TRAIN    loss : 0.05231    f1 : 0.94159\n",
      "Val    loss : 0.12826    f1 : 0.79503\n",
      "epoch : 18/25    time : 379s/2655s\n",
      "TRAIN    loss : 0.04209    f1 : 0.95533\n",
      "Val    loss : 0.16201    f1 : 0.80368\n",
      "epoch : 19/25    time : 379s/2272s\n",
      "TRAIN    loss : 0.04480    f1 : 0.93448\n",
      "Val    loss : 0.19655    f1 : 0.82090\n",
      "epoch : 20/25    time : 378s/1892s\n",
      "TRAIN    loss : 0.06059    f1 : 0.94094\n",
      "Val    loss : 0.16069    f1 : 0.77521\n",
      "epoch : 21/25    time : 381s/1523s\n",
      "TRAIN    loss : 0.04211    f1 : 0.95670\n",
      "Val    loss : 0.14669    f1 : 0.79745\n",
      "epoch : 22/25    time : 379s/1136s\n",
      "TRAIN    loss : 0.06040    f1 : 0.94366\n",
      "Val    loss : 0.16247    f1 : 0.80794\n",
      "epoch : 23/25    time : 378s/756s\n",
      "TRAIN    loss : 0.04250    f1 : 0.95998\n",
      "Val    loss : 0.17568    f1 : 0.80728\n",
      "epoch : 24/25    time : 379s/379s\n",
      "TRAIN    loss : 0.03948    f1 : 0.95229\n",
      "Val    loss : 0.15965    f1 : 0.80711\n",
      "epoch : 25/25    time : 379s/0s\n",
      "TRAIN    loss : 0.04162    f1 : 0.95898\n",
      "Val    loss : 0.18431    f1 : 0.82491\n",
      "----------fold_1 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/25    time : 389s/9343s\n",
      "TRAIN    loss : 1.25039    f1 : 0.16324\n",
      "Val    loss : 0.59678    f1 : 0.23555\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/25    time : 387s/8901s\n",
      "TRAIN    loss : 0.56375    f1 : 0.32367\n",
      "Val    loss : 0.50676    f1 : 0.37107\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/25    time : 388s/8546s\n",
      "TRAIN    loss : 0.41354    f1 : 0.48915\n",
      "Val    loss : 0.35686    f1 : 0.48842\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/25    time : 388s/8148s\n",
      "TRAIN    loss : 0.31909    f1 : 0.58701\n",
      "Val    loss : 0.28410    f1 : 0.57324\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/25    time : 388s/7765s\n",
      "TRAIN    loss : 0.25953    f1 : 0.67364\n",
      "Val    loss : 0.24113    f1 : 0.62173\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/25    time : 387s/7350s\n",
      "TRAIN    loss : 0.18955    f1 : 0.76726\n",
      "Val    loss : 0.23954    f1 : 0.66683\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/25    time : 389s/6998s\n",
      "TRAIN    loss : 0.16107    f1 : 0.77984\n",
      "Val    loss : 0.19653    f1 : 0.75623\n",
      "epoch : 8/25    time : 385s/6540s\n",
      "TRAIN    loss : 0.12154    f1 : 0.84121\n",
      "Val    loss : 0.22297    f1 : 0.68670\n",
      "epoch : 9/25    time : 387s/6184s\n",
      "TRAIN    loss : 0.12011    f1 : 0.85345\n",
      "Val    loss : 0.18621    f1 : 0.75160\n",
      "epoch : 10/25    time : 387s/5798s\n",
      "TRAIN    loss : 0.10636    f1 : 0.85419\n",
      "Val    loss : 0.17702    f1 : 0.75153\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/25    time : 390s/5463s\n",
      "TRAIN    loss : 0.08613    f1 : 0.90584\n",
      "Val    loss : 0.18971    f1 : 0.79331\n",
      "epoch : 12/25    time : 386s/5015s\n",
      "TRAIN    loss : 0.08371    f1 : 0.90099\n",
      "Val    loss : 0.22082    f1 : 0.78447\n",
      "epoch : 13/25    time : 384s/4611s\n",
      "TRAIN    loss : 0.08929    f1 : 0.88718\n",
      "Val    loss : 0.19513    f1 : 0.78128\n",
      "epoch : 14/25    time : 385s/4239s\n",
      "TRAIN    loss : 0.07518    f1 : 0.90185\n",
      "Val    loss : 0.18777    f1 : 0.78153\n",
      "epoch : 15/25    time : 383s/3825s\n",
      "TRAIN    loss : 0.06633    f1 : 0.93069\n",
      "Val    loss : 0.18021    f1 : 0.79004\n",
      "epoch : 16/25    time : 386s/3476s\n",
      "TRAIN    loss : 0.06292    f1 : 0.94257\n",
      "Val    loss : 0.18493    f1 : 0.78469\n",
      "epoch : 17/25    time : 386s/3087s\n",
      "TRAIN    loss : 0.05593    f1 : 0.93929\n",
      "Val    loss : 0.17693    f1 : 0.79271\n",
      "epoch : 18/25    time : 384s/2691s\n",
      "TRAIN    loss : 0.04711    f1 : 0.96101\n",
      "Val    loss : 0.19945    f1 : 0.78859\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/25    time : 386s/2313s\n",
      "TRAIN    loss : 0.04104    f1 : 0.95899\n",
      "Val    loss : 0.16579    f1 : 0.80377\n",
      "-----------------SAVE:20 epoch----------------\n",
      "epoch : 20/25    time : 389s/1943s\n",
      "TRAIN    loss : 0.04952    f1 : 0.95710\n",
      "Val    loss : 0.20501    f1 : 0.80477\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/25    time : 386s/1543s\n",
      "TRAIN    loss : 0.06148    f1 : 0.94290\n",
      "Val    loss : 0.18242    f1 : 0.80954\n",
      "epoch : 22/25    time : 385s/1154s\n",
      "TRAIN    loss : 0.04783    f1 : 0.96974\n",
      "Val    loss : 0.18284    f1 : 0.78696\n",
      "-----------------SAVE:23 epoch----------------\n",
      "epoch : 23/25    time : 385s/771s\n",
      "TRAIN    loss : 0.03315    f1 : 0.97678\n",
      "Val    loss : 0.18576    f1 : 0.82785\n",
      "-----------------SAVE:24 epoch----------------\n",
      "epoch : 24/25    time : 386s/386s\n",
      "TRAIN    loss : 0.03233    f1 : 0.96806\n",
      "Val    loss : 0.13779    f1 : 0.83835\n",
      "epoch : 25/25    time : 384s/0s\n",
      "TRAIN    loss : 0.03105    f1 : 0.96483\n",
      "Val    loss : 0.22644    f1 : 0.78759\n",
      "----------fold_2 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/25    time : 391s/9382s\n",
      "TRAIN    loss : 1.23364    f1 : 0.16261\n",
      "Val    loss : 0.61041    f1 : 0.22838\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/25    time : 383s/8817s\n",
      "TRAIN    loss : 0.54118    f1 : 0.34700\n",
      "Val    loss : 0.46628    f1 : 0.38093\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/25    time : 383s/8425s\n",
      "TRAIN    loss : 0.39389    f1 : 0.51462\n",
      "Val    loss : 0.36357    f1 : 0.54197\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/25    time : 387s/8134s\n",
      "TRAIN    loss : 0.30332    f1 : 0.60557\n",
      "Val    loss : 0.31896    f1 : 0.61324\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/25    time : 380s/7607s\n",
      "TRAIN    loss : 0.24690    f1 : 0.67578\n",
      "Val    loss : 0.25707    f1 : 0.64736\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/25    time : 384s/7299s\n",
      "TRAIN    loss : 0.19195    f1 : 0.75718\n",
      "Val    loss : 0.21910    f1 : 0.68791\n",
      "epoch : 7/25    time : 385s/6924s\n",
      "TRAIN    loss : 0.15926    f1 : 0.78965\n",
      "Val    loss : 0.22600    f1 : 0.68451\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/25    time : 385s/6549s\n",
      "TRAIN    loss : 0.14664    f1 : 0.82290\n",
      "Val    loss : 0.17121    f1 : 0.75095\n",
      "epoch : 9/25    time : 384s/6148s\n",
      "TRAIN    loss : 0.11898    f1 : 0.84592\n",
      "Val    loss : 0.18753    f1 : 0.72217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/25    time : 385s/5770s\n",
      "TRAIN    loss : 0.11206    f1 : 0.86597\n",
      "Val    loss : 0.14726    f1 : 0.80150\n",
      "epoch : 11/25    time : 383s/5361s\n",
      "TRAIN    loss : 0.08823    f1 : 0.90040\n",
      "Val    loss : 0.16129    f1 : 0.78338\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/25    time : 385s/5000s\n",
      "TRAIN    loss : 0.08550    f1 : 0.88364\n",
      "Val    loss : 0.16304    f1 : 0.80535\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/25    time : 385s/4618s\n",
      "TRAIN    loss : 0.07854    f1 : 0.90756\n",
      "Val    loss : 0.16468    f1 : 0.83819\n",
      "epoch : 14/25    time : 386s/4241s\n",
      "TRAIN    loss : 0.05790    f1 : 0.93415\n",
      "Val    loss : 0.14371    f1 : 0.83235\n",
      "epoch : 15/25    time : 384s/3840s\n",
      "TRAIN    loss : 0.06835    f1 : 0.92529\n",
      "Val    loss : 0.14929    f1 : 0.83039\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/25    time : 385s/3467s\n",
      "TRAIN    loss : 0.05747    f1 : 0.94482\n",
      "Val    loss : 0.17647    f1 : 0.84834\n",
      "epoch : 17/25    time : 383s/3061s\n",
      "TRAIN    loss : 0.05373    f1 : 0.95057\n",
      "Val    loss : 0.17901    f1 : 0.82707\n",
      "epoch : 18/25    time : 383s/2681s\n",
      "TRAIN    loss : 0.05152    f1 : 0.94319\n",
      "Val    loss : 0.17253    f1 : 0.75304\n",
      "epoch : 19/25    time : 384s/2307s\n",
      "TRAIN    loss : 0.04991    f1 : 0.94381\n",
      "Val    loss : 0.17413    f1 : 0.79929\n",
      "epoch : 20/25    time : 384s/1921s\n",
      "TRAIN    loss : 0.06074    f1 : 0.93823\n",
      "Val    loss : 0.17974    f1 : 0.76939\n",
      "epoch : 21/25    time : 383s/1533s\n",
      "TRAIN    loss : 0.04976    f1 : 0.94113\n",
      "Val    loss : 0.20446    f1 : 0.76374\n",
      "epoch : 22/25    time : 383s/1149s\n",
      "TRAIN    loss : 0.04719    f1 : 0.95246\n",
      "Val    loss : 0.13887    f1 : 0.80296\n",
      "epoch : 23/25    time : 387s/775s\n",
      "TRAIN    loss : 0.03034    f1 : 0.97055\n",
      "Val    loss : 0.16940    f1 : 0.81274\n",
      "epoch : 24/25    time : 384s/384s\n",
      "TRAIN    loss : 0.02841    f1 : 0.97383\n",
      "Val    loss : 0.15275    f1 : 0.81629\n",
      "epoch : 25/25    time : 386s/0s\n",
      "TRAIN    loss : 0.02811    f1 : 0.97136\n",
      "Val    loss : 0.19335    f1 : 0.82932\n",
      "----------fold_3 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/25    time : 387s/9296s\n",
      "TRAIN    loss : 1.21473    f1 : 0.16274\n",
      "Val    loss : 0.67512    f1 : 0.27606\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/25    time : 385s/8854s\n",
      "TRAIN    loss : 0.56860    f1 : 0.32796\n",
      "Val    loss : 0.43526    f1 : 0.43546\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/25    time : 384s/8441s\n",
      "TRAIN    loss : 0.41664    f1 : 0.46718\n",
      "Val    loss : 0.40563    f1 : 0.51712\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/25    time : 384s/8066s\n",
      "TRAIN    loss : 0.32852    f1 : 0.55988\n",
      "Val    loss : 0.29212    f1 : 0.55781\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/25    time : 383s/7669s\n",
      "TRAIN    loss : 0.26153    f1 : 0.64415\n",
      "Val    loss : 0.31945    f1 : 0.61005\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/25    time : 383s/7286s\n",
      "TRAIN    loss : 0.21111    f1 : 0.74370\n",
      "Val    loss : 0.18945    f1 : 0.70795\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/25    time : 385s/6937s\n",
      "TRAIN    loss : 0.16438    f1 : 0.78340\n",
      "Val    loss : 0.21742    f1 : 0.71502\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/25    time : 384s/6534s\n",
      "TRAIN    loss : 0.13104    f1 : 0.82598\n",
      "Val    loss : 0.18634    f1 : 0.73764\n",
      "epoch : 9/25    time : 381s/6101s\n",
      "TRAIN    loss : 0.10543    f1 : 0.86958\n",
      "Val    loss : 0.19181    f1 : 0.73404\n",
      "epoch : 10/25    time : 382s/5737s\n",
      "TRAIN    loss : 0.09611    f1 : 0.88358\n",
      "Val    loss : 0.21495    f1 : 0.73535\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/25    time : 387s/5411s\n",
      "TRAIN    loss : 0.08699    f1 : 0.88652\n",
      "Val    loss : 0.21456    f1 : 0.75411\n",
      "epoch : 12/25    time : 382s/4968s\n",
      "TRAIN    loss : 0.08105    f1 : 0.90477\n",
      "Val    loss : 0.17882    f1 : 0.73729\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/25    time : 383s/4597s\n",
      "TRAIN    loss : 0.06632    f1 : 0.91906\n",
      "Val    loss : 0.18235    f1 : 0.76971\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/25    time : 386s/4247s\n",
      "TRAIN    loss : 0.07189    f1 : 0.92400\n",
      "Val    loss : 0.23575    f1 : 0.77028\n",
      "epoch : 15/25    time : 384s/3839s\n",
      "TRAIN    loss : 0.06982    f1 : 0.92305\n",
      "Val    loss : 0.20031    f1 : 0.74903\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/25    time : 379s/3410s\n",
      "TRAIN    loss : 0.05926    f1 : 0.92060\n",
      "Val    loss : 0.18640    f1 : 0.78051\n",
      "epoch : 17/25    time : 384s/3069s\n",
      "TRAIN    loss : 0.04509    f1 : 0.95285\n",
      "Val    loss : 0.21231    f1 : 0.75289\n",
      "epoch : 18/25    time : 384s/2685s\n",
      "TRAIN    loss : 0.03887    f1 : 0.95131\n",
      "Val    loss : 0.19092    f1 : 0.78014\n",
      "epoch : 19/25    time : 385s/2310s\n",
      "TRAIN    loss : 0.03980    f1 : 0.95451\n",
      "Val    loss : 0.21731    f1 : 0.76631\n",
      "-----------------SAVE:20 epoch----------------\n",
      "epoch : 20/25    time : 386s/1931s\n",
      "TRAIN    loss : 0.04276    f1 : 0.94633\n",
      "Val    loss : 0.18642    f1 : 0.78742\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/25    time : 384s/1537s\n",
      "TRAIN    loss : 0.06048    f1 : 0.95075\n",
      "Val    loss : 0.16627    f1 : 0.82315\n",
      "epoch : 22/25    time : 383s/1149s\n",
      "TRAIN    loss : 0.02535    f1 : 0.97184\n",
      "Val    loss : 0.17514    f1 : 0.76810\n",
      "epoch : 23/25    time : 384s/768s\n",
      "TRAIN    loss : 0.03526    f1 : 0.96511\n",
      "Val    loss : 0.22747    f1 : 0.77855\n",
      "epoch : 24/25    time : 383s/383s\n",
      "TRAIN    loss : 0.03394    f1 : 0.97559\n",
      "Val    loss : 0.18721    f1 : 0.81744\n",
      "epoch : 25/25    time : 384s/0s\n",
      "TRAIN    loss : 0.04279    f1 : 0.95839\n",
      "Val    loss : 0.13572    f1 : 0.80926\n",
      "----------fold_4 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/25    time : 388s/9314s\n",
      "TRAIN    loss : 1.28115    f1 : 0.16168\n",
      "Val    loss : 0.69341    f1 : 0.21062\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/25    time : 383s/8811s\n",
      "TRAIN    loss : 0.59067    f1 : 0.30238\n",
      "Val    loss : 0.46802    f1 : 0.36639\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/25    time : 382s/8413s\n",
      "TRAIN    loss : 0.42689    f1 : 0.44381\n",
      "Val    loss : 0.34832    f1 : 0.50119\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/25    time : 381s/7999s\n",
      "TRAIN    loss : 0.32483    f1 : 0.55330\n",
      "Val    loss : 0.28115    f1 : 0.59368\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/25    time : 381s/7623s\n",
      "TRAIN    loss : 0.26090    f1 : 0.65847\n",
      "Val    loss : 0.23644    f1 : 0.67394\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/25    time : 383s/7277s\n",
      "TRAIN    loss : 0.18450    f1 : 0.76923\n",
      "Val    loss : 0.19460    f1 : 0.71017\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/25    time : 384s/6906s\n",
      "TRAIN    loss : 0.16202    f1 : 0.79287\n",
      "Val    loss : 0.20149    f1 : 0.71924\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/25    time : 382s/6501s\n",
      "TRAIN    loss : 0.14671    f1 : 0.83466\n",
      "Val    loss : 0.22271    f1 : 0.72995\n",
      "epoch : 9/25    time : 381s/6097s\n",
      "TRAIN    loss : 0.11506    f1 : 0.84906\n",
      "Val    loss : 0.21775    f1 : 0.72887\n",
      "epoch : 10/25    time : 382s/5724s\n",
      "TRAIN    loss : 0.08760    f1 : 0.87332\n",
      "Val    loss : 0.19855    f1 : 0.71883\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/25    time : 383s/5356s\n",
      "TRAIN    loss : 0.10203    f1 : 0.87860\n",
      "Val    loss : 0.21818    f1 : 0.75088\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/25    time : 382s/4968s\n",
      "TRAIN    loss : 0.09238    f1 : 0.89308\n",
      "Val    loss : 0.17266    f1 : 0.77399\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/25    time : 381s/4576s\n",
      "TRAIN    loss : 0.06853    f1 : 0.93019\n",
      "Val    loss : 0.23683    f1 : 0.77451\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/25    time : 382s/4204s\n",
      "TRAIN    loss : 0.07774    f1 : 0.89269\n",
      "Val    loss : 0.18241    f1 : 0.79888\n",
      "epoch : 15/25    time : 380s/3804s\n",
      "TRAIN    loss : 0.05523    f1 : 0.94179\n",
      "Val    loss : 0.18029    f1 : 0.79036\n",
      "epoch : 16/25    time : 382s/3438s\n",
      "TRAIN    loss : 0.05689    f1 : 0.93937\n",
      "Val    loss : 0.20460    f1 : 0.79241\n",
      "epoch : 17/25    time : 383s/3062s\n",
      "TRAIN    loss : 0.05751    f1 : 0.92603\n",
      "Val    loss : 0.19918    f1 : 0.79113\n",
      "epoch : 18/25    time : 383s/2678s\n",
      "TRAIN    loss : 0.04522    f1 : 0.94772\n",
      "Val    loss : 0.19404    f1 : 0.79282\n",
      "epoch : 19/25    time : 385s/2310s\n",
      "TRAIN    loss : 0.04989    f1 : 0.95157\n",
      "Val    loss : 0.16098    f1 : 0.79378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 20/25    time : 386s/1932s\n",
      "TRAIN    loss : 0.03719    f1 : 0.96543\n",
      "Val    loss : 0.17793    f1 : 0.78553\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/25    time : 385s/1540s\n",
      "TRAIN    loss : 0.04510    f1 : 0.95052\n",
      "Val    loss : 0.19699    f1 : 0.83084\n",
      "-----------------SAVE:22 epoch----------------\n",
      "epoch : 22/25    time : 385s/1155s\n",
      "TRAIN    loss : 0.05012    f1 : 0.94480\n",
      "Val    loss : 0.14182    f1 : 0.83669\n",
      "-----------------SAVE:23 epoch----------------\n",
      "epoch : 23/25    time : 388s/776s\n",
      "TRAIN    loss : 0.03785    f1 : 0.96078\n",
      "Val    loss : 0.17263    f1 : 0.83793\n",
      "epoch : 24/25    time : 387s/387s\n",
      "TRAIN    loss : 0.03897    f1 : 0.96072\n",
      "Val    loss : 0.33187    f1 : 0.80832\n",
      "epoch : 25/25    time : 384s/0s\n",
      "TRAIN    loss : 0.03057    f1 : 0.96602\n",
      "Val    loss : 0.16530    f1 : 0.81753\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 42,shuffle=True)\n",
    "batch_size = 10\n",
    "epochs = 25\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay = 2e-2)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, 'best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAdcUcqRDhwf"
   },
   "outputs": [],
   "source": [
    "#model = Network().to(device)\n",
    "\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "\n",
    "\n",
    "#best=0\n",
    "#for epoch in range(epochs):\n",
    "#    start=time.time()\n",
    "#    train_loss = 0\n",
    "#    train_pred=[]\n",
    "#    train_y=[]\n",
    "#    model.train()\n",
    "#    for batch in (train_loader):\n",
    "#        optimizer.zero_grad()\n",
    "#        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "#        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "#        with torch.cuda.amp.autocast():\n",
    "#            pred = model(x)\n",
    "#        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "#        scaler.scale(loss).backward()\n",
    "#        scaler.step(optimizer)\n",
    "#        scaler.update()\n",
    "        \n",
    "#        train_loss += loss.item()/len(train_loader)\n",
    "#        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "#        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "#    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "#    model.eval()\n",
    "#    valid_loss = 0\n",
    "#    valid_pred=[]\n",
    "#    valid_y=[]\n",
    "#    with torch.no_grad():\n",
    "#        for batch in (valid_loader):\n",
    "#            x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "#            y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "#            with torch.cuda.amp.autocast():\n",
    "#                pred = model(x)\n",
    "#            loss = criterion(pred, y)\n",
    "#            valid_loss += loss.item()/len(valid_loader)\n",
    "#            valid_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "#            valid_y += y.detach().cpu().numpy().tolist()\n",
    "#        valid_f1 = score_function(valid_y, valid_pred)\n",
    "#    if valid_f1>=best:\n",
    "#        best=valid_f1\n",
    "#        model_save(model, valid_f1, f'model/eff-b4.pth')\n",
    "#    TIME = time.time() - start\n",
    "#    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "#    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "#    print(f'VALID    loss : {valid_loss:.5f}    f1 : {valid_f1:.5f}    best : {best:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDhj4Ub1Dhwf"
   },
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 10\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load(('best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1]) + np.array(pred_ensemble[2]) + np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/5\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OypD2nftDhwf"
   },
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "#f_pred = []\n",
    "\n",
    "#with torch.no_grad():\n",
    "#    for batch in (test_loader):\n",
    "#        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "#        with torch.cuda.amp.autocast():\n",
    "#            pred = model(x)\n",
    "#        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iZLnGzU_Dhwg"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThAdRC8NDhwg"
   },
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uDFwy3P3Dhwg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vemp_lEADhwg"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"baseline26.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvnePfEfC691"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[BASELINE].ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
